# RAG 假新聞偵測系統 (RAG Fake News Detection System)

一個基於大型語言模型 (LLM) 與檢索增強生成 (RAG) 技術的即時事實查核系統。

## 關於此專案

本專案旨在利用先進的 AI 技術，提供一個能夠對使用者輸入的文本進行即時事實查核的工具。系統會分析輸入的內容，從本地知識庫中檢索相關證據，並由大型語言模型（LLM）判斷其真實性。

整個流程自動化，從查詢理解、證據檢索到最終判斷，為使用者提供有依據的查核結果。

## ✨ 功能亮點

-   **RAG 架構**：整合檢索增強生成 (Retrieval-Augmented Generation) 技術，確保 LLM 的回應有所依據，而不僅是憑空生成。
-   **智慧查詢改寫**：自動將口語化、模糊的用戶查詢改寫為清晰、適合檢索的客觀問題。
-   **混合式檢索 (Hybrid Search)**：結合**向量搜尋**（理解語意）和 **BM25 關鍵字搜尋**（精確匹配），大幅提升證據檢索的準確性與廣度。
-   **考量時效性**：在判斷過程中，會將證據的「發布日期」納入考量，對具有時效性的新聞做出更準確的判斷。
-   **互動式網頁介面**：使用 Streamlit 打造，提供直觀、易用的操作介面，並以醒目的方式呈現最終查核結論。
-   **模組化程式碼**：分為資料抓取、知識庫、推理、使用者介面等模組，易於維護與擴充。

## 🛠️ 技術棧

-   **前端**: Streamlit
-   **大型語言模型 (LLM)**: 透過 Ollama 服務本地運行 (例如：`gemma3:4b`)
-   **向量資料庫**: ChromaDB
-   **嵌入模型 (Embedding Model)**: `shibing624/text2vec-base-chinese`
-   **關鍵字檢索**: `rank_bm25`
-   **網頁爬蟲**: BeautifulSoup, Requests

## 執行範例


## 🚀 開始使用

請依照以下步驟來設定並執行本專案。

### 1. 前提條件

-   已安裝 Python 3.8 或更高版本。
-   已安裝並正在本機背景執行 [Ollama](https://ollama.com/) 服務。
-   已透過 Ollama 下載模型，例如：`ollama run gemma3:4b`。

### 2. 安裝

首先，複製本專案儲存庫，然後進入專案目錄，安裝所有必要的 Python 相依套件：

```bash
# 進入專案根目錄
cd RAG_Fake_News_Detection

# 安裝相依套件
pip install -r requirements.txt
```

### 3. 建立知識庫

在第一次執行應用程式前，您必須先建立本地的知識庫。此步驟會自動抓取最新的事實查核報告並建立索引。

在專案根目錄下執行：
```bash
python main_indexing.py
```
**注意**：此過程可能需要幾分鐘時間，取決於您的網路速度。請確保此步驟成功完成，沒有出現錯誤。

### 4. 啟動應用程式

知識庫建立完成後，執行以下指令來啟動 Streamlit 網頁應用程式：

```bash
streamlit run ui/app.py
```

執行後，您的終端機將提供一個本地網址（通常是 `http://localhost:8501`）。在您的瀏覽器中打開此網址，即可開始使用本系統。

## 📖 使用方式

1.  在文字輸入框中，輸入您想要查核的新聞、文章段落或是一個主張。
2.  點擊「開始查核」按鈕。
3.  系統會首先在頁面頂端顯示「總結報告」，直接告訴您這是真新聞、假新聞、或是資訊不足。
4.  下方會提供詳細的分析過程，包括系統如何拆解您的主張、找到了哪些證據、以及大型語言模型對每一條證據的比對結果。
